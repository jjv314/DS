{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "98bee7eaf09d225730006f2b24ca5662d28cfb65"
   },
   "source": [
    "# Kaggle- Multilayered Perceptron (MLP) implemention on MNIST dataset\n",
    "Untill now we were using the MNIST dataset that is available in torchvision.dataset.Let us now load the dataset from Kaggle repo and train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4e83a9e422c10eb07cbfb779be01803d2b8a5334"
   },
   "outputs": [],
   "source": [
    "# Inserting all the libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset ,DataLoader\n",
    "from torch import nn,optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "PATH=Path(\"../input/digit-recognizer\")\n",
    "print(os.listdir(\"../input/digit-recognizer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "661e23266c2c882d34cdae4c9074d26c0d2ac040"
   },
   "source": [
    "## Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "72b61aac15c29fc295d77130b07d1110c9cb1825"
   },
   "outputs": [],
   "source": [
    "\n",
    "train=pd.read_csv(PATH/'train.csv')\n",
    "test=pd.read_csv(PATH/'test.csv')\n",
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6d5eb02dbfc5e385ffd113560494e0b2275e5f66"
   },
   "source": [
    "## Extracting Input and Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "858a074c0e1dea92562d0f1bd93ff5302f861643"
   },
   "outputs": [],
   "source": [
    "x=train.drop(\"label\",axis=1)\n",
    "y=np.array(train['label'])\n",
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "387109d77b8c6f76d4de868158340faf1a38b2dc"
   },
   "source": [
    "![](http://)![](http://)![](http://)## Normalization FROM HERE[](http://)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b8ff683f50227c31ee39ec05a7bb8b4e2a8c5f94"
   },
   "outputs": [],
   "source": [
    "x_train=x/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "614e6245bdf2e3372dca00d5111b3fbe8e993a64"
   },
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "65e189e8b8c6232146d0dde1fceb773353ad8389"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8f37069db924850a07cd3e98378ae9c61bab1f8f"
   },
   "source": [
    "## Train Test in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "709aaea373c664fad6fd42d8779ae091145b8308"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# same as above but converting it into torch format jj [for new train and validation dataset which is created from original train dataset]\n",
    "# create feature and targets tensor for train set.\n",
    "torch_X_train = torch.from_numpy(x_train.values).type(torch.FloatTensor)\n",
    "torch_y_train = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "\n",
    "# create feature and targets tensor for test set.\n",
    "torch_X_test = torch.from_numpy(x_test.values).type(torch.FloatTensor)\n",
    "torch_y_test = torch.from_numpy(y_test).type(torch.LongTensor)\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\n",
    "test = torch.utils.data.TensorDataset(torch_X_test,torch_y_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "80525db377fe319e7a3fc538ef8b76639c28c995"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Batch size could be used as a variable to change\n",
    "BATCH_SIZE=64\n",
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = False)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "454f4fb8e0a416e60aed471a49850c01a64a77e6"
   },
   "source": [
    "## Train -Test Split -Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d616496f4e453322efe8aecfa71b17fcdddaa8dd"
   },
   "outputs": [],
   "source": [
    "# Either this or the above two cells must be run\n",
    "# working on the same/ here for x and y for the full train dataset\n",
    "torch_X_train = torch.from_numpy(x.values).type(torch.FloatTensor)/255\n",
    "torch_y_train = torch.from_numpy(y).type(torch.LongTensor)\n",
    "myDataset = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\n",
    "valid_no  = int(0.2 * len(myDataset))\n",
    "# so divide the data into trainset and testset\n",
    "trainSet,testSet = torch.utils.data.random_split(myDataset,(len(myDataset)-valid_no,valid_no))\n",
    "print(f\"len of trainSet {len(trainSet)} , len of testSet {len(testSet)}\")\n",
    "batch_size=64\n",
    "train_loader  = DataLoader(trainSet , batch_size=batch_size ,shuffle=True) \n",
    "test_loader  = DataLoader(testSet , batch_size=batch_size ,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a06249ad57104d74d0258fd5972961f720bdc3cf"
   },
   "source": [
    "trainData = torch.from_numpy(x_train.values)\n",
    "trainLabel=torch.from_numpy(y_train)\n",
    "testData = torch.from_numpy(x_test.values)\n",
    "testLabel = torch.from_numpy(y_test)\n",
    "trainData, testData = trainData.type(torch.FloatTensor), testData.type(torch.LongTensor)\n",
    "trainLabel, testLabel = trainLabel.type(torch.FloatTensor), testLabel.type(torch.LongTensor)\n",
    "trainData.shape,testData.shape\n",
    "trainData = trainData.unsqueeze_(dim=1)\n",
    "testData = testData.unsqueeze_(dim=1)\n",
    "trainData.shape,testData.shape\n",
    "#transforms =transforms.Compose(transforms.ToTensor())\n",
    "train_dataset = TensorDataset(trainData,trainLabel)\n",
    "train_loader = DataLoader(train_dataset,batch_size=64,shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(testData,testLabel)\n",
    "test_loader = DataLoader(test_dataset,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "97b2925a24f59b10a16864a76f00e02a4c92b36f"
   },
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8cbe1c508bacadbb875014318a35fed17ab6a3a1"
   },
   "outputs": [],
   "source": [
    "# Architecture of our network\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 100)\n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "        self.fc3 = nn.Linear(100, 10)\n",
    "        #self.fc4 = nn.Linear(100, 10)\n",
    "\n",
    "        # Dropout module with 0.2 drop probability\n",
    "        self.dropout = nn.Dropout(p=0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        # Now with dropout\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        #x = self.dropout(F.relu(self.fc3(x)))\n",
    "\n",
    "        # output so no dropout here\n",
    "        #x = F.log_softmax(self.fc4(x), dim=1)\n",
    "        x = F.log_softmax(self.fc3(x), dim=1)\n",
    "\n",
    "        return x\n",
    "        \n",
    "model=Network()\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.005)\n",
    "criterion=nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2bea512cd5bd9f4f41bd77044f471e644505a5fa"
   },
   "source": [
    "## Train / Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2df4882ed86f9b17b4bba52d56adfde46d1f718d"
   },
   "outputs": [],
   "source": [
    "epochs=10\n",
    "train_losses,test_losses=[],[]\n",
    "for e in range(epochs):\n",
    "    running_loss=0\n",
    "    for images,labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        log_ps=model(images)\n",
    "        loss=criterion(log_ps,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss+=loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss=0\n",
    "        accuracy=0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for images,labels in test_loader:\n",
    "                log_ps=model(images)\n",
    "                test_loss+=criterion(log_ps,labels)\n",
    "                ps=torch.exp(log_ps)\n",
    "                top_p,top_class=ps.topk(1,dim=1)\n",
    "                equals=top_class==labels.view(*top_class.shape)\n",
    "                accuracy+=torch.mean(equals.type(torch.FloatTensor))\n",
    "        model.train()\n",
    "        train_losses.append(running_loss/len(train_loader))\n",
    "        test_losses.append(test_loss/len(test_loader))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "pytorch_total_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
